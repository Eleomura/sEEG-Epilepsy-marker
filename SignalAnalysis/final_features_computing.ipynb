{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d881ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "This code import the pre-processed data in a dictionary, excluding Z1 channel as explained in the report. \n",
    "Then, using first the direct and then the inverse Fourier transform, it computes the time-domain signal corresponding to each \n",
    "frequency interval. Finally, six different signal properties are computed and saved as output.\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d15ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from scipy.fft import fft, fftfreq\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.signal import coherence\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import antropy as ant\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c85b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that interact with .csv files (reading, saving, etc)\n",
    "def read_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all the .csv files inside a folder and stores them in a dictionary. Each key corresponds to the channel names.\n",
    "    \n",
    "    Args:\n",
    "        folder_path : path to the folder in which data are stored\n",
    "        \n",
    "    Returns: \n",
    "        data_dict : dictionary that contains the data\n",
    "    \"\"\"\n",
    "    data_dict = {}  # Initializing an empty dictionary\n",
    "\n",
    "    # read all csv file in folder_path\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.csv') and f != 'Z1.csv'],\n",
    "    key=lambda x: int(x.split('_')[0]) if x.split('_')[0].isdigit() else float('inf'))\n",
    "    \n",
    "    for filename in filenames:\n",
    "        # extract the initial string from file name\n",
    "        initial_string = filename.split('_')[0]\n",
    "\n",
    "        # build the complete path to file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # read .csv file\n",
    "        df = pd.read_csv(file_path, dtype=float)\n",
    "\n",
    "        data_dict[initial_string.replace('.csv', '')] = df.values\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def save_dict_to_csv(dictionary, filename):\n",
    "    \"\"\"\n",
    "    Saves a dictionary as a .csv file\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): dictionary you want to save.\n",
    "        filename (str): name of the .csv file you want to create.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename + \".csv\", 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['Key', 'Value'])  # Scrive la riga dell'intestazione\n",
    "            for key, value in dictionary.items():\n",
    "                writer.writerow([key, value])\n",
    "        print(f\"Il dizionario è stato salvato con successo in {filename}.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel salvataggio del dizionario in {filename}.csv: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58ff9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_component(dictionary, freq_max, freq_min, Fs):\n",
    "    \"\"\"\n",
    "    Filter the signal in order to get the component corresponding to the desired frequency interval\n",
    "    \n",
    "    Args:\n",
    "        dictionary : broad band signal\n",
    "        freq_max : upper limit of the frequency interval\n",
    "        freq_min : lower limit of the frequency interval\n",
    "        Fs : sampling frequency of the signal\n",
    "        \n",
    "    Returns: \n",
    "        dict_components : filtered signal, corresponding to the input frequecy interval, for each key (channel)\n",
    "    \"\"\"\n",
    "    dict_components = {}\n",
    "    for chiave in dictionary.keys():\n",
    "        seg = dictionary[chiave].transpose()\n",
    "        # Appling the hann window in order to reduce spectral leakage\n",
    "        windowed_seg = seg * np.hanning(len(seg))\n",
    "        # Computing the fft \n",
    "        fft_matrix = np.fft.fft(windowed_seg)\n",
    "        fft_res = fft_matrix.reshape(fft_matrix.shape[1])\n",
    "        # Computing the correspondant frequencies\n",
    "        freq = np.fft.fftfreq(len(fft_res), 1.0/Fs)\n",
    "        fft_res[np.logical_or(freq < freq_min, freq >= freq_max)] = 0 #lower value excluded, higher value included\n",
    "        # Compute the inverse fft transform to get the signal in the time-domain\n",
    "        dict_components[chiave] = np.fft.ifft(fft_res)\n",
    "    return dict_components\n",
    "\n",
    "\n",
    "def ampiezza_media_assoluta(signal):\n",
    "    # Compute and return the mean of the absolute value of the signal\n",
    "\n",
    "    return np.mean(np.abs(signal))\n",
    "\n",
    "\"\"\"\"\n",
    "def rms(signal):\n",
    "    return np.sqrt(np.mean(signal**2))\n",
    "\"\"\"\"\n",
    "\n",
    "def varianza(signal):\n",
    "    # Compute and returns the variance of the signal\n",
    "    return np.var(signal)\n",
    "\n",
    "def calcola_bins(data, metodo='sturges'):\n",
    "    \"\"\"\n",
    "    Compute the appropriate number of bins according to the selected method\n",
    "    \n",
    "    Args:\n",
    "        data : signal \n",
    "        metodo: method for thecomputation of the number of bins. Can be sturges, rice, scott, freedman-diaconis\n",
    "        \n",
    "    Returns: \n",
    "        bins: number of bins\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    if metodo == 'sturges':\n",
    "        bins = int(np.ceil(np.log2(n) + 1))\n",
    "    elif metodo == 'rice':\n",
    "        bins = int(np.ceil(2 * n**(1/3)))\n",
    "    elif metodo == 'scott':\n",
    "        bins = int(np.ceil((np.max(data) - np.min(data)) / (3.5 * np.std(data) * n**(-1/3))))\n",
    "    elif metodo == 'freedman-diaconis':\n",
    "        iqr = np.percentile(data.real, 75) - np.percentile(data.real, 25)\n",
    "        bins = int(np.ceil((np.max(data) - np.min(data)) / (2 * iqr * n**(-1/3))))\n",
    "    else:\n",
    "        raise ValueError(\"Metodo non riconosciuto\")\n",
    "    return bins\n",
    "\n",
    "def calcola_entropia(signal):\n",
    "\n",
    "    #Compute and returns the entropy of the signal\n",
    "\n",
    "    # Compute the histogram of the signal using the previous function\n",
    "    bins = calcola_bins(signal, metodo='sturges')\n",
    "    hist, bin_edges = np.histogram(signal, bins=bins, density=True)\n",
    "    #actual entropy computation\n",
    "    return entropy(hist)\n",
    "\n",
    "\n",
    "def hjorth_par(signal):\n",
    "    # compute and returns mobility and complexity of the signal\n",
    "    mobility, complexity = ant.hjorth_params(signal)\n",
    "    return mobility, complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e53c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_features(dictionary,filename):\n",
    "    \"\"\"\n",
    "    Compute some signal features using the previously defined function and saves them in .csv file\n",
    "    \n",
    "    Args:\n",
    "    dictionary: data of each channel\n",
    "    filename : name for the file containing the features\n",
    "    \n",
    "    Returns: none\n",
    "    \"\"\"\n",
    "    features_temp = {}\n",
    "\n",
    "    for chiave in tqdm(dictionary.keys()):\n",
    "        signal = np.array(dictionary[chiave].real)\n",
    "        mobility, complexity = hjorth_par(signal)\n",
    "        features_temp[chiave] = []  # Initializing an empty list for each key\n",
    "        features_temp[chiave].append(ampiezza_media_assoluta(signal))\n",
    "        features_temp[chiave].append(rms(signal))\n",
    "        features_temp[chiave].append(varianza(signal))\n",
    "        features_temp[chiave].append(mobility)\n",
    "        features_temp[chiave].append(complexity)\n",
    "        features_temp[chiave].append(calcola_entropia(signal))  \n",
    "        features_temp[chiave].append(ant.num_zerocross(signal)) \n",
    "\n",
    "    try:\n",
    "        # writing the dictionary with the features in a .csv file\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['key','amplitude','rms', 'variance', 'mobility', 'complexity', 'entropy','num_zerocross']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for key, values in features_temp.items():\n",
    "                writer.writerow({\n",
    "                    'key': key,\n",
    "                    'amplitude': values[0],\n",
    "                    'rms' : values[1],\n",
    "                    'variance' : values[2],\n",
    "                    'mobility' : values[3],\n",
    "                    'complexity': values[4],\n",
    "                    'entropy': values[5],\n",
    "                    'num_zerocross': values[6],\n",
    "                })\n",
    "\n",
    "        print(f\"Il dizionario è stato salvato con successo in {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel salvataggio del dizionario in {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4798c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['J1', 'J2', 'J3', 'J4', 'J5', 'L1', 'L10', 'L11', 'L12', 'L13', 'L14', 'L15', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'M1', 'M2', 'M3', 'M4', 'M5', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'O10', 'O11', 'O13', 'O5', 'O6', 'O7', 'O8', 'O9', 'R1', 'R2', 'R3', 'X1', 'X2', 'X3', 'X4', 'Z1', 'Z2', 'Z3', 'Z4', 'Z5', 'Z6'])\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# Read .csv file and creates EPI dictionary\n",
    "dizionario_EPI = read_csv_files('dati_finali_EPI')\n",
    "#check the dictionary\n",
    "print(dizionario_EPI.keys())\n",
    "print(len(dizionario_EPI.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9786d913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A1', 'A10', 'A11', 'A12', 'A13', 'A14', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'F1', 'F10', 'F11', 'F12', 'F2', 'F3', 'F6', 'F7', 'F8', 'F9', 'G1', 'G10', 'G11', 'G12', 'G13', 'G14', 'G2', 'G3', 'G4', 'H1', 'H10', 'H11', 'H12', 'H2', 'H3', 'H4', 'H7', 'H8', 'H9', 'I1', 'I10', 'I2', 'I3', 'I7', 'I8', 'I9', 'J14', 'J15', 'J16', 'J17', 'J18', 'M15', 'M16', 'M17', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15', 'N16', 'N17', 'N18', 'O1', 'O12', 'O2', 'O3', 'O4', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'R10', 'R11', 'R12', 'R13', 'R14', 'R15', 'R16', 'R7', 'R8', 'R9', 'T1', 'T2', 'T3', 'T4', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X5', 'X6', 'Y1', 'Y10', 'Y11', 'Y2', 'Y5', 'Y6', 'Y7', 'Y8', 'Y9', 'Z10', 'Z11', 'Z12', 'Z13', 'Z14', 'Z15', 'Z16'])\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "# Read .csv file and creates NON EPI dictionary\n",
    "dizionario_NONEPI = read_csv_files('dati_finali_NON_EPI')\n",
    "#check the dictionary\n",
    "print(dizionario_NONEPI.keys())\n",
    "print(len(dizionario_NONEPI.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35083926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a1fc706ef94aa6aa958a72875341e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_delta_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529da74738ef4084b323402f5eb651cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_delta_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "# DELTA WAVES \n",
    "# filtering the siganl\n",
    "dizionario_delta_EPI = spectral_component(dizionario_EPI,4,0.4,500)\n",
    "dizionario_delta_NONEPI = spectral_component(dizionario_NONEPI,4, 0.4,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_delta_EPI,'features_delta_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_delta_NONEPI,'features_delta_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "746d1246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dc065a6fc746e2b01482ebf3093ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_theta_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6f4c71b8ba4903a63e25f798d4e9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_theta_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "# THETA WAVES\n",
    "# filtering the signal\n",
    "dizionario_theta_EPI = spectral_component(dizionario_EPI,8,4,500)\n",
    "dizionario_theta_NONEPI = spectral_component(dizionario_NONEPI,8, 4,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_theta_EPI,'features_theta_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_theta_NONEPI,'features_theta_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2208371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad44e42c74d494db568422daaee8881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_alpha_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc4d75c689b4170a7278aa6b553bd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_alpha_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "#ALPHA WAVES\n",
    "# filtering the signal\n",
    "dizionario_alpha_EPI = spectral_component(dizionario_EPI,13,8,500)\n",
    "dizionario_alpha_NONEPI = spectral_component(dizionario_NONEPI,13, 8,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_alpha_EPI,'features_alpha_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_alpha_NONEPI,'features_alpha_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc2fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a7098b520c4793adfadbe9fde3e74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_beta_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de3b990efc146d3816872faf9f96bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_beta_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "#BETA WAVES\n",
    "# filtering the signal\n",
    "dizionario_beta_EPI = spectral_component(dizionario_EPI,30,13,500)\n",
    "dizionario_beta_NONEPI = spectral_component(dizionario_NONEPI,30, 13,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_beta_EPI,'features_beta_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_beta_NONEPI,'features_beta_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8ba1878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31e6ed03ac042d795284ba3d05c48c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma1_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506c08f710bb4c6b85d57338d80a1028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma1_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "#GAMMA 1 WAVES\n",
    "# filtering the signal\n",
    "dizionario_gamma1_EPI = spectral_component(dizionario_EPI,50,30,500)\n",
    "dizionario_gamma1_NONEPI = spectral_component(dizionario_NONEPI,50, 30,500)\n",
    "#Computing and saving the features\n",
    "\n",
    "compute_and_save_features(dizionario_gamma1_EPI,'features_gamma1_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_gamma1_NONEPI,'features_gamma1_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0f64633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c8133e624645eaa5e23f74dcc7c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma2_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400a46ff43a740089c86ef9af576710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma2_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "#GAMMA 2 WAVES\n",
    "# filtering the signal\n",
    "dizionario_gamma2_EPI = spectral_component(dizionario_EPI,70,50,500)\n",
    "dizionario_gamma2_NONEPI = spectral_component(dizionario_NONEPI,70, 50,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_gamma2_EPI,'features_gamma2_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_gamma2_NONEPI,'features_gamma2_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e03b625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b7267e0a8b4ea88eef6e3f7a99b6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma3_EPI_testdata.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de910d55cd37494cbe2451efe041c84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma3_NONEPI_testdata.csv\n"
     ]
    }
   ],
   "source": [
    "# GAMMA 3 WAVES\n",
    "# filtering the signal\n",
    "dizionario_gamma3_EPI = spectral_component(dizionario_EPI,90,70,500)\n",
    "dizionario_gamma3_NONEPI = spectral_component(dizionario_NONEPI,90, 70,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_gamma3_EPI,'features_gamma3_EPI_testdata.csv')\n",
    "compute_and_save_features(dizionario_gamma3_NONEPI,'features_gamma3_NONEPI_testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39bfa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c26b72059345bc9dbca7186d801a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma4_EPI.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1694af5aae074ddb90a985dba703d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dizionario è stato salvato con successo in features_gamma4_NONEPI.csv\n"
     ]
    }
   ],
   "source": [
    "#GAMMA 4 WAVES\n",
    "# filtering the signal\n",
    "dizionario_gamma4_EPI = spectral_component(dizionario_EPI,150,90,500)\n",
    "dizionario_gamma4_NONEPI = spectral_component(dizionario_NONEPI,150, 90,500)\n",
    "#Computing and saving the features\n",
    "compute_and_save_features(dizionario_gamma4_EPI,'features_gamma4_EPI.csv')\n",
    "compute_and_save_features(dizionario_gamma4_NONEPI,'features_gamma4_NONEPI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb91231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
